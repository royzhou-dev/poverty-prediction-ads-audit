# Poverty Prediction ADS Audit

## Background
A Kaggle competition hosted by the Inter-American Development Bank (IDB) called for an improvement to their income qualification system which they use to allocate financial resources. Social programs often have difficulty ensuring that the right people are given appropriate resources. This is especially challenging in impoverished areas where families lack income and expense records. A popular solution is the Proxy Means Test (PMT), a model that considers a family’s observable household attributes to predict the household’s level of need. However, as population grows and poverty declines the accuracy of this model has deteriorated.

One of the proposed improvements is an automated decision system that employs VotingClassifiers to determine poverty level. We chose this ADS based on its performance in the Kaggle competition and the votes it received from the community. Given the importance and potential impact of the ADS, it is crucial to ensure that the ADS is both accurate and fair.

When evaluating the accuracy and fairness, there are several trade-offs that need to be considered, such as between the false positive rate and true positive rate. While some may argue that it’s preferable to occasionally provide aid to a wealthier household to ensure that no poor households miss out, this approach could be incredibly costly and divert resources from those who need it. On the other hand, if the ADS is too strict in its criteria for poverty, many impoverished families may be overlooked. Therefore, there needs to be an appropriate balance to guarantee that we are effectively and equitably distributing resources to those in need.

## Input and Output
The data was provided directly by the IDB in the form of CSVs. There are 142 columns, with 9,557 rows in the training dataset and 23,856 rows in the validation dataset. Each row represents an individual. Each individual also has a household ID that represents the household they belong to. Other features include house wall material, renting situation, electricity sources, etc. Most of the variables are categorical and are one-hot encoded so they only take values 0 or 1. Therefore, most variables are represented by integers or floats. 

The relationships between the features can be visualized using a heatmap, which shows the magnitude and direction of the relationship between features using a gradient color scale. Because we have 141 features, we created a heatmap of only the most correlated features. In general, we found that features are very weakly correlated with one another. The features that are highly correlated with one another are usually the result of the one-hot encoding. For example, there are four features related to where the household gets its electricity from which are all highly correlated. 

![image](images/heatmap.png)

Helper functions from ydata-profiling were used to better understand the relationships between features. We found that certain features had really high correlations, such as v2a1 (monthly rent) and pisoother (material of the floor), and r4h3 (total males) and r4h2 (males ages 12 and under). Some of this information might be redundant, but it could be helpful in gauging the ratio of children to adults in a household, and also give a rough idea of the ages of the individuals of a household. We also found some features that were heavily imbalanced. For instance, v14a (whether the household had a bathroom) was made up of 99% 1s, meaning that almost no households lacked a bathroom. This was also the case with paredfibras (whether the predominant material of walls was natural fibers).

The target class is the poverty level of a household. Specifically, the model outputted a number 1 through 4, with 1 indicating extreme poverty and 4 indicating a non-vulnerable household. Households labeled 1, 2, or 3 suggest that a certain amount of aid is needed while households labeled non-vulnerable households shouldn't receive any aid. Interestingly, our training dataset is extremely imbalanced, with more households labeled 4 than households labeled 1, 2, and 3 combined. 

![image](images/targets.png)

## Implementation

The first step in the ADS was to clean and preprocess it. This involved converting objects to numeric types. Only a handful of features are represented with objects rather than integers or floats. One example is edjefe/edjefa, which represents the years of education for the male and female heads of the household respectively, which should be represented by a number, but because many people replied “yes” or “no”, this feature is represented by a string. In addition, inconsistencies in the data were attempted to be fixed. For example, separate individuals from the same household would answer differently whether or not the household has a bathroom. These inconsistencies were fixed by making conclusions based on the other features. So if the household does not have running water, it’s safe to assume that they also do not have toilets. Preprocessing the data included the following steps:
- Creating new columns to represent relationships between other columns i.e. 'working_man_fraction" was created by (working males) / (total persons in household). A potential concern with this method is discrimination on sensitive features, namely gender. The dataset lacks data about women in general, so this method groups working women, non-working women, and children all into the same group, while not doing so to men.
- Feature transformation by converting one-hot encoded columns into label encoding. A potential issue with this is the introduction of ordinal relationships between categorical variables. Larger values might weigh more in the model and can therefore add bias.
- In the case of years of education for the male and female heads of household, "yes" was replaced with value 4. This method of imputation discriminates against women who on average had more years of education (8.78 vs. 8.48). Since women have a higher average, replacing missing values with 4 for both groups is unfair for women.
![image](images/education_distributions.png)
